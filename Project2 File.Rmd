---
title: "Project 2"
author: "Nicole Levin"
date: "2022-09-29"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
Start playing around with functions and queries.
```{r}
library(httr)
library(dplyr)
library(jsonlite)
library(tidyverse)
my_beer <- GET("https://api.openbrewerydb.org/breweries?by_name=cooper")
str(my_beer, max.level=1)
parsed <- fromJSON(rawToChar(my_beer$content))
str(parsed, max.level=1)
summary_info <- as_tibble(parsed %>% select(id, name, state))

# Allow user to select a word in name and optional argument of number of results
name_search <- function(name, num_results=NA){
  name <- tolower(name)
  if (is.numeric(num_results)){
    search_num <- paste0("&per_page=", num_results)
   search_url <- paste0("https://api.openbrewerydb.org/breweries?by_name=", name, search_num)
  }
  else { 
    search_url <- paste0("https://api.openbrewerydb.org/breweries?by_name=", name)
  }
  search_run <- GET(search_url)
}

#Run a test case
test_case <- name_search(name="city")
parsed <- fromJSON(rawToChar(test_case$content))
str(parsed, max.level=1)
summary_info_test <- as_tibble(parsed %>% select(id, name, state, city, brewery_type))

#Function to search by type with an option for number of results
type_search <- function(type, num_results=NA){
  type <- tolower(type)
  if (is.numeric(num_results)){
    search_num <- paste0("&per_page=", num_results)
   search_url <- paste0("https://api.openbrewerydb.org/breweries?by_type=", type, search_num)
  }
  else { 
    search_url <- paste0("https://api.openbrewerydb.org/breweries?by_type=", type)
  }
  search_run <- GET(search_url)
}

test_case2 <- type_search(type="Regional", 4)
parsed2 <- fromJSON(rawToChar(test_case2$content))
str(parsed2, max.level=1)
summary_info_test2 <- as_tibble(parsed2 %>% select(id, name, state, city, brewery_type))

#Function to convert state abbreviations to full state names. Finish out with all of the states if this is a functionality we want to have.
state_conversion <- function(state){
  ifelse(state = "AL", state_name = "Alabama", ifelse(state = "AK", state_name = "Alaska",   ifelse(state="AZ", state_name = "Arizona", ifelse(state= "AK", state_name = "Arkansas", state_name=state))))
}
  
state_search <- function(state_name, num_results=NA){
  state_name <- tolower(state_name)
  state_name <- sub(" ", "_", state_name)
  if (is.numeric(num_results)){
    search_num <- paste0("&per_page=", num_results)
   search_url <- paste0("https://api.openbrewerydb.org/breweries?by_state=", state_name, search_num)
  }
  else { 
    search_url <- paste0("https://api.openbrewerydb.org/breweries?by_state=", state_name)
  }
  search_run <- GET(search_url)
}

#Test it out
test_case3 <- state_search(state_name = "New York", 10)
parsed3 <- fromJSON(rawToChar(test_case3$content))
str(parsed3, max.level=1)
summary_info_test3 <- as_tibble(parsed3 %>% select(id, name, state, city, brewery_type))

#Goal of the next section is to create of function that takes a state, runs queries for all of the brewery types with the plan of plotting a barchart of the results. This gets long because of the maximum of 50 results per search.

type_count <- function(state_name){
  state_name <- tolower(state_name)
  state_name <- sub(" ", "_", state_name)
  
  #Get number of micro breweries
  search_url_micro <- paste0("https://api.openbrewerydb.org/breweries?by_state=", state_name, "&by_type=micro&per_page=50")
  search_run_micro <- GET(search_url_micro)
  parsed_micro <- fromJSON(rawToChar(search_run_micro$content))
  total_micro <- nrow(parsed_micro)
  if(total_micro==50){search_url_micro2 <- paste0("https://api.openbrewerydb.org/breweries?by_state=", state_name, "&by_type=micro&page=2&per_page=50")
  search_run_micro2 <- GET(search_url_micro2)
  parsed_micro2 <- fromJSON(rawToChar(search_run_micro2$content))
  total_micro <- nrow(parsed_micro2) + total_micro}
  if(total_micro==100){search_url_micro3 <- paste0("https://api.openbrewerydb.org/breweries?by_state=", state_name, "&by_type=micro&page=3&per_page=50")
  search_run_micro3 <- GET(search_url_micro3)
  parsed_micro3 <- fromJSON(rawToChar(search_run_micro3$content))
  total_micro <- nrow(parsed_micro3) + total_micro}
  if(total_micro==150){search_url_micro4 <- paste0("https://api.openbrewerydb.org/breweries?by_state=", state_name, "&by_type=micro&page=4&per_page=50")
  search_run_micro4 <- GET(search_url_micro4)
  parsed_micro4 <- fromJSON(rawToChar(search_run_micro4$content))
  total_micro <- nrow(parsed_micro4) + total_micro}
  #may need to  use if logic or a while loop to get all results for micro
  search_url_nano <- paste0("https://api.openbrewerydb.org/breweries?by_state=", state_name, "&by_type=nano&per_page=50")
  if(total_micro==200){search_url_micro5 <- paste0("https://api.openbrewerydb.org/breweries?by_state=", state_name, "&by_type=micro&page=5&per_page=50")
  search_run_micro5 <- GET(search_url_micro5)
  parsed_micro5 <- fromJSON(rawToChar(search_run_micro5$content))
  total_micro <- nrow(parsed_micro5) + total_micro}
  search_run_nano <- GET(search_url_nano)
  parsed_nano <- fromJSON(rawToChar(search_run_nano$content))
  total_nano <- nrow(parsed_nano)
  if(total_micro==250){search_url_micro6 <- paste0("https://api.openbrewerydb.org/breweries?by_state=", state_name, "&by_type=micro&page=6&per_page=50")
  search_run_micro6 <- GET(search_url_micro6)
  parsed_micro6 <- fromJSON(rawToChar(search_run_micro6$content))
  total_micro <- nrow(parsed_micro6) + total_micro}
  if(total_micro==300){search_url_micro7 <- paste0("https://api.openbrewerydb.org/breweries?by_state=", state_name, "&by_type=micro&page=7&per_page=50")
  search_run_micro7 <- GET(search_url_micro7)
  parsed_micro7 <- fromJSON(rawToChar(search_run_micro7$content))
  total_micro <- nrow(parsed_micro7) + total_micro}
  if(total_micro==350){search_url_micro8 <- paste0("https://api.openbrewerydb.org/breweries?by_state=", state_name, "&by_type=micro&page=8&per_page=50")
  search_run_micro8 <- GET(search_url_micro8)
  parsed_micro8 <- fromJSON(rawToChar(search_run_micro8$content))
  total_micro <- nrow(parsed_micro8) + total_micro}
  if(total_micro==400){search_url_micro9 <- paste0("https://api.openbrewerydb.org/breweries?by_state=", state_name, "&by_type=micro&page=9&per_page=50")
  search_run_micro9 <- GET(search_url_micro9)
  parsed_micro9 <- fromJSON(rawToChar(search_run_micro9$content))
  total_micro <- nrow(parsed_micro9) + total_micro}
  if(total_micro==450){search_url_micro10 <- paste0("https://api.openbrewerydb.org/breweries?by_state=", state_name, "&by_type=micro&page=10&per_page=50")
  search_run_micro10 <- GET(search_url_micro10)
  parsed_micro10 <- fromJSON(rawToChar(search_run_micro10$content))
  total_micro <- nrow(parsed_micro10) + total_micro}
  
  #Get number of nano breweries
  search_url_nano <- paste0("https://api.openbrewerydb.org/breweries?by_state=", state_name, "&by_type=nano&per_page=50")
  search_run_nano <- GET(search_url_nano)
  parsed_nano <- fromJSON(rawToChar(search_run_nano$content))
  total_nano <- nrow(parsed_nano)
  
  #Get number of regional breweries
  search_url_regional <- paste0("https://api.openbrewerydb.org/breweries?by_state=", state_name, "&by_type=regional&per_page=50")
  search_run_regional <- GET(search_url_regional)
  parsed_regional <- fromJSON(rawToChar(search_run_regional$content))
  total_regional <- nrow(parsed_regional)
  
  #Get number of brew pubs
   search_url_brewpub <- paste0("https://api.openbrewerydb.org/breweries?by_state=", state_name, "&by_type=brewpub&per_page=50")
  search_run_brewpub <- GET(search_url_brewpub)
  parsed_brewpub <- fromJSON(rawToChar(search_run_brewpub$content))
  total_brewpub <- nrow(parsed_brewpub)
  search_url_brewpub2 <- paste0("https://api.openbrewerydb.org/breweries?by_state=", state_name, "&by_type=brewpub&page=2&per_page=50")
  search_run_brewpub2 <- GET(search_url_brewpub2)
  parsed_brewpub2 <- fromJSON(rawToChar(search_run_brewpub2$content))
  total_brewpub <- nrow(parsed_brewpub2) + total_brewpub
  search_url_brewpub3 <- paste0("https://api.openbrewerydb.org/breweries?by_state=", state_name, "&by_type=brewpub&page=3&per_page=50")
  search_run_brewpub3 <- GET(search_url_brewpub3)
  parsed_brewpub3 <- fromJSON(rawToChar(search_run_brewpub3$content))
  total_brewpub <- nrow(parsed_brewpub3) + total_brewpub
  search_url_brewpub4 <- paste0("https://api.openbrewerydb.org/breweries?by_state=", state_name, "&by_type=brewpub&page=4&per_page=50")
  search_run_brewpub4 <- GET(search_url_brewpub4)
  parsed_brewpub4 <- fromJSON(rawToChar(search_run_brewpub4$content))
  total_brewpub <- nrow(parsed_brewpub4) + total_brewpub
  search_url_brewpub5 <- paste0("https://api.openbrewerydb.org/breweries?by_state=", state_name, "&by_type=brewpub&page=5&per_page=50")
  search_run_brewpub5 <- GET(search_url_brewpub5)
  parsed_brewpub5 <- fromJSON(rawToChar(search_run_brewpub5$content))
  total_brewpub <- nrow(parsed_brewpub5) + total_brewpub
  
  #Get number of large breweries
  search_url_large <- paste0("https://api.openbrewerydb.org/breweries?by_state=", state_name, "&by_type=large&per_page=50")
  search_run_large <- GET(search_url_large)
  parsed_large <- fromJSON(rawToChar(search_run_large$content))
  total_large <- nrow(parsed_large)
  return(list(micro=total_micro, nano=total_nano, regional=total_regional, brewpub=total_brewpub, large=total_large))
}

test_case4 <- type_count("california")




#Just a test search to throw different options in
test <- GET("https://api.openbrewerydb.org/breweries?by_state=california&by_type=brewpub&page=5&per_page=50") 
parsed_test <- fromJSON(rawToChar(test$content))
summary_info_test <- as_tibble(parsed_test %>% select(id, name, state, city, brewery_type))
```

Running into issues with no numeric data. I'll switch gears to food for a bit.
```{r}
#My API key c93de7d29d41461eac0f5e8272839b6e 

#Query for banana with 20 results
food_test <- GET("https://api.spoonacular.com/recipes/findByIngredients?ingredients=banana&apiKey=c93de7d29d41461eac0f5e8272839b6e")
parsed_food_test <- fromJSON(rawToChar(food_test$content))

#Grab what I care about
food_test_results <- as_tibble(parsed_food_test) %>% select(title)

#Query based on nutrition
food_test2 <- GET("https://api.spoonacular.com/recipes/findByNutrients?minCarbs=1&maxCarbs=50&number=20&apiKey=c93de7d29d41461eac0f5e8272839b6e")
parsed_food_test2 <- fromJSON(rawToChar(food_test2$content))
food_test2_results <- as_tibble(parsed_food_test2) %>% select(id, title, calories, protein, fat, carbs)

#Plot fat vs. calories
g <- ggplot(data=food_test2_results, aes(x=calories, y=fat))
g + geom_point()

#Plot carbs vs calories
g <- ggplot(data=food_test2_results, aes(x=calories, y=carbs))
g + geom_point()

#Plot protein vs calories
g <- ggplot(data=food_test2_results, aes(x=calories, y=protein))
g + geom_point()

#Plot carbs vs fat
g <- ggplot(data=food_test2_results, aes(x=fat, y=carbs))
g + geom_point()

#Create new variables, a carb/calories ratio and a macro-nutrient variable
food_test2_results$protein <- extract_numeric(food_test2_results$protein)
food_test2_results$carbs <- extract_numeric(food_test2_results$carbs)
food_test2_results$fat <- extract_numeric(food_test2_results$fat)
food_test2_results <- food_test2_results %>% mutate("ratio" = carbs/calories, "macros"= carbs + calories + protein)

#Cuisine search
food_test3 <- GET("https://api.spoonacular.com/recipes/complexSearch?query=pasta&cuisine=italian&number=2&apiKey=c93de7d29d41461eac0f5e8272839b6e")
parsed_food_test3 <- fromJSON(rawToChar(food_test3$content))
food_test3_results <- parsed_food_test3$results

#Taking IDs found before, get some more info. My goal right now is to get a combination of numeric and categorical variables
combo_search <- paste0("https://api.spoonacular.com/recipes/", food_test2_results$id[2], "/information?includeNutrition=false&apiKey=c93de7d29d41461eac0f5e8272839b6e")
food_test4 <- GET(combo_search)
parsed_food_test4 <- fromJSON(rawToChar(food_test4$content))
food_test4_results <- c(parsed_food_test4$weightWatcherSmartPoints, parsed_food_test4$healthScore, parsed_food_test4$pricePerServing, parsed_food_test4$id, parsed_food_test4$title, parsed_food_test4$readyInMinutes)

#Try something similar, but with bulk. Can use this to get nutrition info, but the parsing might be hard.
#Get list of IDs from a previous search
id_list <- paste(as.character(food_test2_results$id[1:10]), collapse=",")
bulk_search <- paste0("https://api.spoonacular.com/recipes/informationBulk?ids=", id_list, "&includeNutrition=false&apiKey=c93de7d29d41461eac0f5e8272839b6e")
food_test5 <- GET(bulk_search)
parsed_food_test5 <- fromJSON(rawToChar(food_test5$content))
str(parsed_food_test5, levels=1)
food_test5_results <- as_tibble(parsed_food_test5) %>% select(id, title, glutenFree, dairyFree, vegetarian, aggregateLikes, healthScore, weightWatcherSmartPoints, sourceName, pricePerServing, readyInMinutes)
combined_results <- as_tibble(c(food_test5_results, food_test2_results[1:10,3:8]))
combined_results <- combined_results %>% mutate(WW_category = if_else(weightWatcherSmartPoints <10, 1, if_else(weightWatcherSmartPoints <20, 2, 3))) 
factor(combined_results$WW_category, levels = c(1, 2, 3), labels = c("low", "medium", "high"))
combined_results <- combined_results %>% mutate(time_category = if_else(readyInMinutes <= 15, "quick", if_else(readyInMinutes <= 45, "medium", "long")))
#My general thought is to use a nutrition or ingredient search to get a list of IDs to use for the rest of the searching and analysis. We can pull Weight Watchers points, price per serving, ready in minutes, health score, price per serving, ready in minutes, and aggregate likes as quantitative data. Potential options for some categorical stuff are vegetarian, gluten free, dairy free, source name. Can use cuisines, dish types, diets possibly, but those may be hard to parse.

#Can use the categorical data of gluten free, vegetarian, and dairy free for contingency tables
#Can look at whether anything seems to correlate with aggregate likes: health score, price per serving, ready in minutes, calories.
#Can create box plot based on whatever numeric thing we want, break out into vegetarian and not, gluten free and not, dairy free and not.
#Break into categories and get summary statistics. Average health score for vegetarian, average fat for gluten free, etc.
#Create categorical variable for ready in minutes. 0-15: quick, >15-45: average, >45: long
#Create categorical WW Points: 0-10=low, >10-20=medium, >20=high

#One set of options to achieve minimum plot requirements: (1) Scatterplot of something vs aggregate likes or something vs health score, (2)box plots of health scores by vegetarian and not, (3) bar plot of categorized ready minutes or WW Points and pick a variable to group by like gluten free, (4) histogram of health score or calories, plus a 5th of some type.

#Plots for example. First, some scatterplot options.
g <- ggplot(combined_results, aes(x=calories, y=healthScore))
g + geom_point()

g <- ggplot(combined_results, aes(x=calories, y=aggregateLikes))
g + geom_point()

#Next box plot of calories broken out by vegetarian and not
g <- ggplot(combined_results, aes(x=vegetarian, y=calories))
g + geom_boxplot()

#Next a bar plot.
g <- ggplot(combined_results, aes(x=WW_category))
g + geom_bar(aes(fill=vegetarian), position="dodge")

#Next a histogram
g <- ggplot(combined_results, aes(x=calories))
g + geom_histogram()

#Try a search with a bunch of options to see if it works.
new_test2 <- GET("https://api.spoonacular.com/recipes/findByIngredients?ingredients=banana&findByNutrients?minCalories=500&maxCalories=1500&apiKey=c93de7d29d41461eac0f5e8272839b6e")

parsed_new_test2 <- fromJSON(rawToChar(new_test2$content))
new_test_results2 <- as_tibble(parsed_new_test2) %>% select(id, title)


```

Now I want to create functions to do stuff
```{r}
#User options for search. Can input: (1)ingredient for search, (2)Minimum calories, (3)Maximum calories, (4)random=FALSE, (5)skip, (6)Number of results.

ingredient_search <- function(ingredient, number=10){
  ingredient <- tolower(ingredient)
  search_url <- paste0("https://api.spoonacular.com/recipes/findByIngredients?ingredients=", ingredient,"&number=", number, "&apiKey=c93de7d29d41461eac0f5e8272839b6e")
  search_result <- GET(search_url)
  parsed_search_result <- fromJSON(rawToChar(search_result$content))
  id_list <- paste(as.character(parsed_search_result$id), collapse=",")
}

#Run a test
ingredient_test <- ingredient_search("apple", 5)

calorie_search <- function(min_calories=0, max_calories=5000, random=FALSE, number=10){
  if(random==FALSE){
    search_url <- paste0("https://api.spoonacular.com/recipes/findByNutrients?minCalories=",min_calories,"&maxCalories=",max_calories,"&number=", number, "&apiKey=c93de7d29d41461eac0f5e8272839b6e")}
  else {search_url <- paste0("https://api.spoonacular.com/recipes/findByNutrients?minCalories=",min_calories,"&maxCalories=",max_calories,"&number=", number, "&random=true&apiKey=c93de7d29d41461eac0f5e8272839b6e")}
  search_result <- GET(search_url)
  parsed_search_result <- fromJSON(rawToChar(search_result$content))
  id_list <- paste(as.character(parsed_search_result$id), collapse=",")
}

#Now for either result, we'll do the searching to pull in additional info
bulk_url <- paste0("https://api.spoonacular.com/recipes/informationBulk?ids=", id_list, "&includeNutrition=false&apiKey=c93de7d29d41461eac0f5e8272839b6e")
bulk_search <- GET(bulk_url)
parsed_bulk_search <- fromJSON(rawToChar(bulk_search$content))
results_df <- as_tibble(parsed_bulk_search) %>% select(id, title, glutenFree, dairyFree, vegetarian, aggregateLikes, healthScore, weightWatcherSmartPoints, sourceName, pricePerServing, readyInMinutes)
results_df <- results_df %>% mutate(WW_category = if_else(weightWatcherSmartPoints <10, 1, if_else(weightWatcherSmartPoints <20, 2, 3))) 
factor(combined_results$WW_category, levels = c(1, 2, 3), labels = c("low", "medium", "high"))




  
```

